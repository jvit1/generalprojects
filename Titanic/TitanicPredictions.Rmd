```{r}
library(tidyverse)
library(tidymodels)
library(modelr)
library(randomForest)
train <- read.csv("C:/Users/student/Documents/UVA/Portfolio Projects/generalprojects/Titanic/train.csv")
test <- read.csv("C:/Users/student/Documents/UVA/Portfolio Projects/generalprojects/Titanic/test.csv")
```

```{r}
train <- train %>% select(-Name) %>% drop_na()

RF.mod1 <- randomForest(Survived ~ ., data = train,
                        mtry = 2, importance = TRUE)


## Random forest information
## No. of variables shows the number of variables available for each split
## OOB estimate of error rate is an estimate of misclassification
## Misclassification error shown for each level with confusion matrix
RF.mod1


## Importance of predictor variables
## The values show the percent decrease in the following measures when each variable is not 
## available for a split 
##   a. prediction accuracy for each level of the response variable
##   b. overall prediction accuracy
##   c. node purity
RF.mod1 %>% 
  importance()


## Build random forest without seller_type
RF.mod2 <- randomForest(Survived ~ Pclass + Sex + Age + Fare, data = train,
                        mtry = 2, importance = TRUE)


## Random forest information
RF.mod2

RF.mod2 %>% 
  importance()

## Add predicted values to VALIDATION data
## Change default column names
## Potential issue: 
##   When the data is split, it is possible that a category that is present in one set is not 
##   present in other sets. In this case, prediction will not work.
RF.add1 <- train %>%
  add_predictions(RF.mod1) %>%
  rename(pred_pct = pred) %>%
  mutate(method = "RF.mod1") %>%
  mutate(prediction = ifelse(pred_pct > .5, 1,0))

RF.add2 <- train %>%
  add_predictions(RF.mod2) %>%
  rename(pred_pct = pred) %>%
  mutate(method = "RF.mod2") %>%
  mutate(prediction = ifelse(pred_pct > .5, 1,0))


## Combine prediction informatio

RF.add1$Survived <- as.factor(RF.add1$Survived)
RF.add1$prediction <- as.factor(RF.add1$prediction)
RF.add2$Survived <- as.factor(RF.add2$Survived)
RF.add2$prediction <- as.factor(RF.add2$prediction)

RF.add <- RF.add1 %>%
  bind_rows(RF.add2) %>%
  group_by(method)
## Confusion matrix
## Use validation data
RF.add1 %>%
  conf_mat(truth = Survived, estimate = prediction)

RF.add2 %>%
  conf_mat(truth = Survived, estimate = prediction)


## Accuracy rate
## Use validation data
RF.add %>%
  metrics(truth = Survived, estimate = prediction) %>%
  filter(.metric == "accuracy")
```

Adding to testing data
```{r}
RF.test <- test %>%
  add_predictions(RF.mod1) %>%
  rename(pred_pct = pred) %>%
  mutate(method = "RF.mod1") %>%
  mutate(prediction = ifelse(pred_pct > .5, 1,0))

final.results <- RF.test %>%
  select(PassengerId, prediction)

write.csv(final.results, 'C:/Users/student/Documents/UVA/Portfolio Projects/generalprojects/Titanic/results.csv' , row.names=FALSE)
```

